---
title: 敏捷开发相关
toc: true
typora-copy-images-to: ../../gitbooks/static/images/
mathjax: true
abbrlink: 754a2167
date: 2017-12-28
tags:
  - Interview
categories:
  - Interview
---



DevOps是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。下面为大家分享DevOps系列的面试问题





持续整合问题







问题一：







**持续集成是什么意思？** 



我将建议您通过给出持续集成（CI）的小定义来开始这个答案。这是一种开发实践，要求开发人员每天多次将代码集成到共享存储库中。然后通过自动构建验证每个签入，允许团队尽早发现问题。 我建议您解释一下如何在以前的工作中实施它。您可以参考下面给出的示例：



![img](https://www.itcodemonkey.com/data/upload/portal/20180822/1534922246147288.jpg)



在上图中：



开发人员将代码签入其私有工作区。 完成后，他们将更改提交到共享存储库（版本控制存储库）。 CI服务器监视存储库并在发生更改时检出更改。 然后，CI服务器将提取这些更改并构建系统，并运行单元和集成测试。 CI服务器现在将通知团队成功构建。 如果构建或测试失败，CI服务器将向团队发出警报。 该团队将尽早解决问题。 这个过程不断重复。





问题二：







**为什么需要开发和测试的持续集成？**



对于这个问题，您应该关注持续集成的需求。我的建议是在你的答案中提到以下解释： 开发和测试的持续集成通过在完成所有开发之后替换传统的测试实践来提高软件质量，并减少交付时间。它允许开发团队尽早检测和定位问题，因为开发人员需要每天多次（更频繁地）将代码集成到共享存储库中。然后自动测试每个登记入住。





问题三：







**持续集成的成功因素是什么？** 



在这里，您必须提到持续集成的要求。您可以在答案中包含以下几点：



维护代码存储库 自动化构建 使构建自我测试 每个人每天承诺到基线 应该构建每个提交（到基线） 保持快速构建 在生产环境的克隆中进行测试 让您轻松获得最新的可交付成果 每个人都可以看到最新版本的结果 





问题四：







**解释如何将Jenkins从一台服务器移动或复制到另一台服务器？** 



我将通过将jobs目录从旧服务器复制到新服务器来完成此任务。有多种方法可以做到这一点; 你可以：



只需复制相应的作业目录，即可将作业从一个Jenkins安装移动到另一个。 通过使用其他名称克隆作业目录来制作现有作业的副本。 通过重命名目录来重命名现有作业。请注意，如果更改作业名称，则需要更改尝试调用重命名作业的任何其他作业。





问题五：







**解释如何在Jenkins中创建备份和复制文件？** 



要创建备份，您需要做的就是定期备份JENKINS_HOME目录。这包含所有构建作业配置，从属节点配置和构建历史记录。要创建Jenkins设置的备份，只需复制此目录即可。您还可以复制作业目录以克隆或复制作业或重命名目录。





问题六：







**解释如何设置Jenkins工作？** 



首先提一下如何创建Jenkins的工作。转到Jenkins首页，选择“New Job”，然后选择“Build a free-style software project”。 然后你可以告诉这个自由式工作的元素：



可选的SCM，例如源代码所在的CVS或Subversion。 用于控制Jenkins何时执行构建的可选触发器。 某种构建脚本，用于执行实际工作的构建（ant，maven，shell脚本，批处理文件等）。 从构建中收集信息的可选步骤，例如归档工件和/或记录javadoc和测试结果。 使用构建结果通知其他人/系统的可选步骤，例如发送电子邮件，IM，更新问题跟踪器等。





问题七：







你如何保护Jenkins？ 



我保证Jenkins的方式如下所述。如果您有任何其他方式，请在下面的评论部分中提及：



确保Jenkins与我公司的用户目录与适当的插件集成。 确保启用矩阵/项目矩阵以微调访问。 使用自定义版本控制脚本自动化在Jenkins中设置权限/特权的过程。 限制对Jenkins数据/文件夹的物理访问。 定期对其进行安全审核。





持续测试面试问题







问题一：







**什么是连续测试？** 



我将建议您遵循下面提到的解释： 持续测试是执行自动化测试的过程，作为软件交付管道的一部分，以获得与最新构建相关的业务风险的即时反馈。通过这种方式，每个构建都会持续测试，允许开发团队获得快速反馈，以便他们可以防止这些问题进入软件交付生命周期的下一阶段。这大大加快了开发人员的工作流程，因为无需手动重建项目并在进行更改后重新运行所有测试。





问题二：







**什么是自动化测试？**



自动化测试或测试自动化是自动化手动过程以测试被测应用程序/系统的过程。 自动化测试涉及使用单独的测试工具，使您可以创建可以重复执行的测试脚本，而不需要任何手动干预。





问题三：







**自动化测试有哪些好处？** 



我列举了自动化测试的一些优点。在您的答案中包含这些内容，您可以添加自己的经验，了解Continuous Testing如何提供帮助：



支持执行重复的测试用例 有助于测试大型测试矩阵 启用并行执行 鼓励无人看管的执行 提高准确性，从而减少人为产生的错误 节省时间和金钱





问题四：







**如何在DevOps生命周期中自动化测试？**



我在下面提到了一个通用流程，您可以参考： 在DevOps中，开发人员需要将源代码中的所有更改提交到共享存储库。像Jenkins这样的持续集成工具每次在代码中进行更改时都会从此共享存储库中提取代码，并将其部署到Selenium等工具进行的连续测试中，如下图所示。 通过这种方式，与传统方法不同，代码中的任何更改都会不断进行测试。



![img](https://www.itcodemonkey.com/data/upload/portal/20180822/1534922246368715.png)



问题五：







**为什么持续测试对DevOps很重要？**

 

您可以通过说“连续测试允许立即测试代码中的任何更改来回答这个问题。这避免了在周期结束时进行“大爆炸”测试所产生的问题，例如发布延迟和质量问题。通过这种方式，持续测试可以促进更频繁和更好的质量发布。







**问题六：**







**连续测试工具的关键要素是什么？** 



连续测试的关键要素是：



风险评估：它涵盖风险缓解任务，技术债务，质量评估和测试覆盖范围优化，以确保构建准备好向下一阶段发展。

 

策略分析：确保所有流程符合组织不断发展的业务和合规性要求。 



可追溯性：确保满足真正的要求，不需要返工。对象评估用于确定哪些需求存在风险，按预期工作或需要进一步验证。 



高级分析：它在静态代码分析，变更影响分析和范围评估/优先级划分等领域使用自动化，以便首先防止缺陷并在每次迭代中完成更多任务。 



测试优化：它确保测试产生准确的结果并提供可操作的结果。方面包括测试数据管理，测试优化管理和测试维护 



服务虚拟化：它确保访问真实的测试环境。服务可视化使您能够访问所需测试阶段的虚拟表单，从而缩短测试环境设置和可用性的浪费时间。





问题七：







**您熟悉哪种测试工具以及该工具的优点是什么？** 



这里提到您使用的测试工具，并相应地构建您的答案。我在下面提到了一个例子： 我曾在Selenium上工作以确保高质量和更频繁的发布。



Selenium的一些优点是：



它是免费和开源的 它拥有庞大的用户群和帮助社区 它具有跨浏览器兼容性（Firefox，Chrome，Internet Explorer，Safari等） 它具有出色的平台兼容性（Windows，Mac OS，Linux等） 它支持多种编程语言（Java，C＃，Ruby，Python，Pearl等） 它有新的和定期的存储库开发 它支持分布式测试





问题八：







**Selenium支持哪些测试类型？** 



Selenium支持两种类型的测试：

- 回归测试：它是在修复错误的区域周围重新测试产品的行为。 
- 功能测试：它指的是单独测试软件功能（功能点）。





问题九：







**什么是Selenium IDE？** 



我的建议是通过定义Selenium IDE来开始这个答案。它是Selenium脚本的集成开发环境。它作为Firefox扩展实现，允许您记录，编辑和调试测试。Selenium IDE包含整个Selenium Core，允许您在他们将运行的实际环境中轻松快速地记录和回放测试。 现在，您的答案中包含一些优势。凭借自动完成支持和快速移动命令的能力，无论您喜欢何种类型的测试，Selenium IDE都是创建Selenium测试的理想环境。





问题十：







**Selenium中的Assert和Verify命令有什么区别？** 



下面提到了Assert和Verify命令之间的区别：



断言命令检查给定条件是真还是假。假设我们断言给定元素是否存在于网页上。如果条件为真，则程序控制将执行下一个测试步骤。但是，如果条件为false，则执行将停止，并且不会执行进一步的测试。 Verify命令还会检查给定条件是true还是false。无论条件是真还是假，程序执行都不会停止，即验证期间的任何故障都不会停止执行，并且所有测试步骤都将被执行。





问题十一







**如何使用WebDriver启动浏览器？**



以下语法可用于启动Browser：

```
WebDriver driver = new FirefoxDriver（）; 
WebDriver driver = new ChromeDriver（）; 
WebDriver driver = new InternetExplorerDriver（）;
```





问题十二：







**我什么时候应该使用Selenium Grid？** 



对于这个答案，我的建议是给出Selenium Grid的一个小定义。它可以用于在多个平台和浏览器上同时执行相同或不同的测试脚本，以实现分布式测试执行。这允许在不同环境下进行测试并显着节省执行时间。

#  



配置管理面试问题







问题一：







**配置管理流程的目标是什么？** 



配置管理（CM）的目的是通过使开发或部署过程可控和可重复，确保产品或系统在其整个生命周期中的完整性，从而创建更高质量的产品或系统。 CM流程允许有序管理系统信息和系统更改，以便：

修改能力， 提高性能， 可靠性或可维护性， 延长寿命， 降低成本， 降低风险 责任或正确的缺陷。





问题二：







**资产和配置项有什么区别？** 



我认为，你应该首先解释资产。它具有财务价值以及附加的折旧率。IT资产只是它的一个子集。任何具有成本的组织和组织都将其用于资产价值计算和税收计算中的相关收益属于资产管理，此类项目称为资产。 另一方面，配置项可能有也可能没有分配给它的财务值。它不会有任何与之相关的折旧。因此，它的生命不依赖于其财务价值，而是取决于该项目对该组织过时的时间。



然后，您可以举例说明两者之间的相似性和差异：

-  1）相似性： 服务器 - 它既是资产又是CI。
-  2）差异： 构建 - 这是一种资产，但不是CI。





问题三:







**IAC如何适用于DevOps方法？它实现了什么目的****？**



作为代码的基础架构（IAC）是一种IT基础架构，运营团队可以使用它来自动管理和通过代码进行配置，而不是使用手动过程。 更快部署的公司会将软件等基础设施视为可以使用DevOps工具和流程管理的代码。利用这些工具，您可以更轻松，快速，安全，可靠地更改基础架构





问题四：







**Puppet，Chef，SaltStack和Ansible中哪一个是最好的配置管理（CM）工具？为什么？**



这取决于组织的需求，因此在所有这些工具上提到几点：



Puppet是最古老，最成熟的CM工具。Puppet是一个基于Ruby的配置管理工具，虽然它有一些免费功能，但Puppet很棒的大部分内容仅在付费版本中可用。不需要大量额外功能的组织会发现Puppet很有用，但那些需要更多自定义的组织可能需要升级到付费版本。 



Chef是用Ruby编写的，因此可以由熟悉该语言的人定制。它还包括免费功能，如果需要，还可以从开源升级到企业级。最重要的是，它是一个非常灵活的产品。



Ansible是一个非常安全的选项，因为它使用Secure Shell。它是一个简单的工具，但除了配置管理之外，它还提供了许多其他服务。它非常容易学习，因此非常适合那些没有专职IT人员但仍需要配置管理工具的人。 



SaltStack是基于python的开源CM工具，适用于大型企业，但其学习曲线相当低。





问题五：







**什么是Puppet？**



建议你先给出一个小小的Puppet定义。它是一个配置管理工具，用于自动执行管理任务。 现在您应该描述其架构以及Puppet如何管理其代理。Puppet具有主从架构，其中Slave必须首先向Master发送证书签名请求，并且Master必须签署该证书以便在Puppet Master和Puppet Slave之间建立安全连接，如下图所示。Puppet Slave向Puppet Master和Puppet Master发送请求，然后在Slave上推送配置。 请参阅下面的图解释上述说明。



![img](https://www.itcodemonkey.com/data/upload/portal/20180822/1534922247738371.jpg)





问题六:







**在客户端使用Puppet Master进行身份验证之前，需要对其证书进行签名和接受。你将如何自动完成这项任务？**

 
最简单的方法是在puppet.conf中启用自动签名。 请注意这是一个安全风险。如果你还想这样做：



把Puppet master加入防火墙 - 限制端口tcp / 8140只限于你信任的网络。 为每个“信任区域”创建puppet master，并且只在该Puppet master清单中包含受信任的节点。 





问题七：







**描述通过Puppet自动化流程所取得的最重要的收益。** 



建议你解释一下你过去使用Puppet的经历。您可以参考以下示例： 我使用Puppet自动配置和部署Linux和Windows机器。除了将处理时间从一周缩短到10分钟之外，我还使用了角色和配置文件模式，并在README中记录了每个模块的用途，以确保其他人可以使用Git更新模块。我写的模块仍然在使用，但是我的团队成员和社区成员对它们进行了改进





问题八：







**您使用哪些开源或社区工具来使Puppet更强大？** 



在这里，您需要提及工具以及如何使用这些工具使Puppet更强大。以下是一个供您参考的示例： 变更和请求通过Jira出票，我们通过内部流程管理请求。然后，我们使用Git和Puppet的Code Manager应用程序根据最佳实践管理Puppet代码。此外，我们使用烧杯测试框架通过Jenkins中的持续集成管道运行所有Puppet更改。





问题九：







**什么是Puppet清单？** 



这是一个非常重要的问题，所以请确保您正确的流程。据我说，你应该首先定义清单。每个节点（或Puppet Agent）都在Puppet Master中获得了配置细节，用本机Puppet语言编写。这些细节用Puppet可以理解的语言编写，称为Manifest。它们由Puppet代码组成，其文件名使用.pp扩展名。 现在举个例子。您可以在Puppet Master中编写一个清单，用于创建文件并在连接到Puppet Master的所有Puppet Agent（Slaves）上安装apache。





问题十：







**什么是Puppet模块以及它与Puppet Manifest的不同之处？** 



对于这个答案，您可以使用下面提到的解释： Puppet模块是清单和数据（例如事实，文件和模板）的集合，它们具有特定的目录结构。模块对于组织Puppet代码很有用，因为它们允许您将代码拆分为多个清单。使用Modules来组织几乎所有的Puppet清单是最佳实践。 Puppet程序称为Manifest，它由Puppet代码组成，其文件名使用.pp扩展名。





问题十一：







**什么是Puppet的Facter？** 



你应该回答Facter在Puppet中做了什么，所以根据我的说法，你应该说：Facter收集有关Puppet Agent的基本信息（事实），例如硬件细节，网络设置，操作系统类型和版本，IP地址，MAC地址， SSH密钥等等。这些事实随后在Puppet Master的Manifests中作为变量提供。





问题十二：







**什么是Chef？** 



通过定义Chef来开始这个答案。它是一个功能强大的自动化平台，可将基础架构转换为代码 Chef是一个工具，您可以编写用于自动化流程的脚本。 现在您可以解释Chef的架构，它包括：

- Chef Server：Chef Server是基础架构配置数据的中央存储。Chef Server存储配置节点所需的数据并提供搜索，这是一个功能强大的工具，允许您根据数据动态驱动节点配置。
- Chef Node： Node是使用Chef-client配置的任何主机。Chef-client在您的节点上运行，与Chef Server联系以获取配置节点所需的信息。由于Node是运行Chef-client软件的机器，因此节点有时被称为“客户端”。
- Chef Workstation： Chef Workstation是您用来修改cookbook和其他配置数据的主机。



![img](https://www.itcodemonkey.com/data/upload/portal/20180822/1534922247694092.jpg)





问题十三：







**Chef中的资源是什么？** 



我的建议是首先定义资源。资源代表一个基础架构及其所需的状态，例如应安装的软件包，应运行的服务或应生成的文件。 您应该解释资源的功能，包括以下几点：



描述配置项的所需状态。 声明将该项目置于所需状态所需的步骤。 指定资源类型，例如包，模板或服务。 根据需要列出其他详细信息（也称为资源属性）。 分组为配方，描述工作配置。





**问题十四：**







**Chef的recipe是什么意思？**



对于这个答案，我建议你使用上面提到的流程：首先定义recipe。Recipe是描述特定配置或策略的资源集合。配方描述了配置系统部分所需的一切。 定义之后，通过包括以下几点来解释食谱的功能：



安装和配置软件组件。 管理文件。 部署应用程序。 执行其他食谱。





问题十五:







**Cookbook与Chef中的recipe有何不同？** 



对此的答案非常直接。您可以简单地说，recipe是资源的集合，主要配置软件包或某些基础设施。Cookbook将recipe和其他信息整合在一起，比单独使用recipe更易于管理。





问题十六：







**如何查看所有ansible_变量的列表？** 



Ansible默认收集有关被管理机器的“事实”，这些事实可以在Playbooks和模板中访问。要查看有关计算机的所有可用事实的列表，可以将“设置”模块作为临时操作运行：

```
Ansible -m setup hostname
```

这将打印出所有可用事实的字典对于那个特定的主人。





问题十七：







**如何设置应用程序的部署顺序？** 



WebLogic Server 8.1允许您选择应用程序的加载顺序。WebLogic Server在部署应用程序之前部署服务器级资源（第一个JDBC，然后是JMS）。应用程序按以下顺序部署：



连接器，然后是EJB，然后是Web应用程序。如果应用程序是EAR，则按照在application.xml部署描述符中声明它们的顺序加载各个组件。





问题十八：







**是否可以刷新已部署应用程序的静态组件而无需重新部署整个应用程序？** 

是的，您可以使用weblogic.Deployer指定组件并使用以下语法定位服务器：

```
java weblogic.Deployer -adminurl http：// admin：7001 -name appname -targets server1，server2 -deploy jsps / * .jsp
```





问题十九：







**如何关闭自动部署功能？** 



自动部署功能每三秒检查一次应用程序文件夹，以确定是否有任何新应用程序或对现有应用程序的任何更改，然后动态部署这些更改。



为在开发模式下运行的服务器启用了自动部署功能。要禁用自动部署功能，请使用以下方法之一将服务器置于生产模式：



在管理控制台中，单击左窗格中的域名，然后在右窗格中选择“生产模式”复选框。 在命令行中，在启动域的管理服务器时包括以下参数：

```
-Dweblogic.ProductionModeEnabled = tru
```

为给定域中的所有WebLogic Server实例设置生产模式。





问题二十：







**我什么时候应该使用externalstage选项？** 



如果您想自己暂存应用程序，请使用weblogic.Deployer设置-externalstage，并通过自己希望的方式将其复制到目标。





持续监控面试问题







问题一：







**为什么需要持续监控？** 



建议您采用下面提到的流程： 

持续监控可以及时发现问题或缺陷，并采取快速纠正措施，有助于降低组织的费用。 



持续监控提供解决方案，解决三个操作规程，称为：

- 持续审计 
- 连续控制监测 
- 持续交易检查





问题二：







**什么是Nagios？** 



您可以通过首先提到Nagios是监控工具之一来回答这个问题。它用于DevOps文化中的系统，应用程序，服务和业务流程等的连续监视。



如果发生故障，Nagios可以向技术人员发出问题警报，允许他们在中断影响业务流程，最终用户或客户之前开始修复流程。使用Nagios，您无需解释为什么不可见的基础架构中断会影响您组织的底线。 现在，一旦定义了Nagios，您就可以提到使用Nagios可以实现的各种功能。 通过使用Nagios，您可以：

- 在过时的系统导致故障之前规划基础架构升级。 
- 在出现问题的第一个迹象时应答问题。 
- 检测到问题时自动修复问题。 
- 协调技术团队的回应。 
- 确保您的组织的SLA得到满足。 
- 确保IT基础架构中断对组织的底线影响最小。 
- 监控整个基础架构和业务流程。 



这就完成了这个问题的答案。可以根据讨论的方向添加诸如优点等的进一步细节。





问题三：







**Nagios如何运作？** 



建议你按照下面的解释来解答这个问题： Nagios在服务器上运行，通常作为守护进程或服务运行。Nagios会定期运行驻留在同一服务器上的插件，它们会联系您网络或Internet上的主机或服务器。可以使用Web界面查看状态信息。如果发生某些事情，您还可以收到电子邮件或短信通知 Nagios守护程序的行为类似于在某些时刻运行某些脚本的调度程序。它存储这些脚本的结果，并在这些结果发生变化时运行其他脚本。





问题四：







**什么是Nagios的插件？** 



通过定义插件开始这个答案。它们是脚本（Perl脚本，Shell脚本等），可以从命令行运行以检查主机或服务的状态。Nagios使用插件的结果来确定网络上主机和服务的当前状态。 一旦定义了插件，解释为什么我们需要插件。只要需要检查主机或服务的状态，Nagios就会执行插件。插件将执行检查，然后只是将结果返回给Nagios。Nagios将处理从插件接收的结果并采取必要的操作。





问题五：







**Nagios中的NRPE（Nagios Remote Plugin Executor）是什么？** 



对于这个问题，给出插件的简要定义。NRPE插件旨在允许您在远程Linux / Unix计算机上执行Nagios插件。这样做的主要原因是允许Nagios监视远程计算机上的“本地”资源（如CPU负载，内存使用情况等）。由于这些公共资源通常不会暴露给外部计算机，因此必须在远程Linux / Unix计算机上安装NRPE之类的代理。



我将建议您根据下图所示解释NRPE架构。NRPE插件由两部分组成：

check_nrpe插件，驻留在本地监视机器上。 NRPE守护程序，在远程Linux / Unix机器上运行。 

监视主机和远程主机之间存在SSL（安全套接字层）连接，如下图所示。

![img](https://www.itcodemonkey.com/data/upload/portal/20180822/1534922247253519.png)





问题六：







**你对Nagios的被动检查是这么理解的？** 



我认为，答案应该从解释被动检查开始。它们由外部应用程序/进程启动和执行，被动检查结果将提交给Nagios进行处理。 然后解释被动检查的必要性。它们对于监视异步性服务非常有用，并且无法通过定期轮询其状态来有效监控。它们还可用于监视位于防火墙后面的服务，并且无法从监视主机主动检查。





问题七：







**Nagios何时检查外部命令？** 



我建议你按照下面提到的流程。Nagios在以下条件下检查外部命令：

由主配置文件中的commandcheckinterval选项指定的定期间隔，或 事件处理程序执行后立即执行。这是外部命令检查的常规循环的补充，并且在事件处理程序向Nagios提交命令时提供立即操作。





问题八：







**Nagios中的主动和被动检查有什么区别？** 



对于这个问题，首先指出主动和被动检查的基本区别。主动检查和被动检查之间的主要区别在于Active检查由Nagios启动和执行，而被动检查由外部应用程序执行。 如果您的面试官看起来不相信上述说明，那么您还可以提及主动和被动检查的一些关键功能： 被动检查对于监控以下服务非常有用：



本质上是异步的，无法通过定期轮询其状态来有效监控。 位于防火墙后面，无法从监控主机主动检查。 Actives检查的主要功能如下：

- Nagios流程启动主动检查。 
- 主动检查定期运行。





问题九：







**Nagios如何帮助分布式监控？**



面试官将期待你回答与Nagios的分布式架构相关的答案。因此，我建议您以下面的方式回答： 使用Nagios，您可以使用分布式监控方案监控整个企业，Nagios的本地从属实例执行监控任务并将结果报告给单个主站。您可以管理主服务器的所有配置，通知和报告，而从服务器完成所有工作。这种设计利用了Nagios利用被动检查的能力，即外部应用程序或将结果发送回Nagios的过程。在分布式配置中，这些外部应用程序是Nagios的其他实例。





问题十：







**解释Nagios的主要配置文件及其位置？** 



首先提一下这个主配置文件包含的内容及其功能。主配置文件包含许多影响Nagios守护程序运行方式的指令。Nagios守护程序和CGI都读取此配置文件（它指定主配置文件的位置）。 现在您可以知道它的存在位置以及创建方式。运行configure脚本时，将在Nagios分发的基本目录中创建示例主配置文件。主配置文件的默认名称是nagios.cfg。它通常放在Nagios安装的etc /子目录中（即/ usr / local / nagios / etc /）。





问题十一：







**解释Flaip Detection在Nagios中的工作原理？** 



我会建议你先解释Flapping。当服务或主机过于频繁地更改状态时会发生抖动，这会导致大量问题和恢复通知。 定义Flapping后，解释Nagios如何检测Flapping。每当Nagios检查主机或服务的状态时，它将检查它是否已经开始或停止振荡。Nagios遵循以下给定的程序来做到这一点：



- 存储分析历史检查结果的主机或服务的最后21次检查的结果，并确定状态更改/转换发生的位置 使用状态转换来确定主机或服务的百分比状态更改值（更改度量） 比较百分比状态变化值与低和高拍打阈值 当主机或服务的百分比状态变化首次超过高振荡阈值时，确定主机或服务已开始振荡。 
- 当主机或服务的百分比状态低于低抖动阈值时，确定主机或服务已停止振荡。





问题十二：







**在Nagios中影响递归和继承的三个主要变量是什么？** 



根据我的说法，这个答案的正确格式应该是： 首先命名变量，然后对每个变量做一个小解释：



名称 使用 寄存器 然后给出每个变量的简要说明。Name是其他对象使用的占位符。使用定义应使用其属性的“父”对象。寄存器的值可以为0（表示只有模板）和1（实际对象）。寄存器值永远不会被继承。





问题十三：







**为什么说Nagios是面向对象？**



Nagios的一个特性是对象配置格式，因为您可以创建从其他对象定义继承属性的对象定义，从而创建名称。这简化并阐明了各个组件之间的关系。





问题十四：







**什么是Nagios的状态跟踪？** 



我会建议你先介绍一下State Salking。它用于记录目的。当为特定主机或服务启用Stalking时，Nagios将非常仔细地观察该主机或服务，并记录它在检查结果输出中看到的任何更改。 根据您和访调员之间的讨论，您还可以添加“在以后分析日志文件时非常有用。在正常情况下，只有在主机或服务自上次检查后状态发生变化时，才会记录主机或服务检查的结果。“





容器化和虚拟化面试问题







问题一：







**什么是容器？**



我的建议是首先解释容器化的必要性，容器用于提供从开发人员的笔记本电脑到测试环境，从登台环境到生产的一致计算环境。 现在给出容器的定义，一个容器由一个完整的运行时环境组成：一个应用程序，以及它所有的依赖项，库和其他二进制文件，以及运行它所需的配置文件，捆绑到一个包中。容纳应用程序平台及其依赖项消除了操作系统分发和底层基础架构的差异。

![img](https://www.itcodemonkey.com/data/upload/portal/20180822/1534922247547004.png)





问题二：







**容器化相比虚拟化有哪些优势？**



以下是容器化优于虚拟化的优势：



容器提供实时配置和可扩展性，但VM提供缓慢的配置 与VM相比，容器是轻量级的 与容器相比，VM的性能有限 与VM相比，容器具有更好的资源利用率





问题三：







**什么是Docker镜像？**



我建议你使用下面提到的流程： Docker镜像是Docker容器的来源。换句话说，Docker镜像用于创建容器。使用build命令创建映像，并且在使用run启动时它们将生成容器。图像存储在Docker注册表中，例如registry.hub.docker.com，因为它们可能变得非常大，图像被设计为由其他图像层组成，允许在通过网络传输图像时发送最少量的数据。 提示：请注意Dockerhub以回答有关预先可用图像的问题。





问题四：







**什么是Docker容器？** 



这是一个非常重要的问题，所以请确保不要偏离主题。我建议您遵循下面提到的格式： Docker容器包括应用程序及其所有依赖项，但与其他容器共享内核，作为主机操作系统上用户空间中的独立进程运行。Docker容器不依赖于任何特定的基础架构：它们可以在任何计算机，任何基础架构和任何云中运行。 现在解释如何创建Docker容器，可以通过创建Docker映像然后运行它来创建Docker容器，也可以使用Dockerhub上存在的Docker映像。 Docker容器基本上是Docker镜像的运行时实例。





问题五：







**什么是Docker hub？**



Docker hub是一个基于云的注册表服务，允许您链接到代码存储库，构建映像并测试它们，存储手动推送的映像以及指向Docker云的链接，以便您可以将映像部署到主机。它为整个开发流程中的容器映像发现，分发和变更管理，用户和团队协作以及工作流自动化提供了集中资源。





问题六：







**Docker与其他容器技术有何不同？** 



我认为，您的答案应该包含以下几点：Docker容器易于在云中部署。与其他技术相比，它可以在相同的硬件上运行更多应用程序，使开发人员可以轻松快速创建，可立即运行的容器化应用程序，并使管理和部署应用程序变得更加容易。您甚至可以与您的应用程序共享容器。 如果你还有一些要点可以添加，你可以这样做，但要确保上面的解释在你的答案中。





问题七：







**什么是Docker Swarm？**



 你应该通过解释Docker Swarn来开始这个答案。它是Docker的本机群集，它将Docker主机池转变为单个虚拟Docker主机。Docker Swarm提供标准的Docker API，任何已经与Docker守护进程通信的工具都可以使用Swarm透明地扩展到多个主机。 我还建议您添加一些支持的工具：

Dokku Docker Compose Docker Machine Jenkins





问题八：







**Dockerfile用于什么？** 



我认为，应该从解释Dockerfile的使用开始。Docker可以通过读取Dockerfile中的指令自动构建图像。 现在我建议你给出一个Dockerfle的小定义。Dockerfile是一个文本文档，其中包含用户可以在命令行上调用以组合图像的所有命令。使用docker构建用户可以创建一个连续执行多个命令行指令的自动构建。





问题九：







**我可以在Docker中使用json而不是yaml作为我的compose文件吗？** 



你可以使用json而不是yaml作为你的compose文件，使用带有compose的json文件，指定用于例如的文件名：

```
docker-compose -f docker-compose.json up
```





问题十：







**Docker容器可以扩展多远？** 



像谷歌和Twitter这样的大型网络部署，以及像Heroku和dotCloud这样的平台提供商都运行在容器技术上，并行运行数十万甚至数百万个容器。





问题十一：







**当Docker容器退出时，我会丢失数据吗？**



当Dcoker容器退出时，不会丢失数据。在您明确删除容器之前，应用程序写入磁盘的任何数据都会保留在其容器中。即使容器停止，容器的文件系统仍然存在。





其它问题







问题一：







**HTTP如何工作？** 



与大多数其他协议一样，HTTP协议在客户端和服务器模型中工作。用于发起请求的Web浏览器被称为客户端，并且响应该请求的Web服务器软件被称为服务器。万维网联盟和互联网工程任务组是HTTP协议标准化的两个重要方面。HTTP允许在中间体（例如网关，代理或隧道）的帮助下改进其请求和响应。使用HTTP协议可以请求的资源可以使用称为URL（统一资源定位符）的特定类型的URI（统一资源标识符）来获得。TCP（传输控制协议）用于建立到HTTP使用的应用层端口80的连接。





问题二：







**如何使软件可部署？** 



编写软件系统安装和重新配置脚本的能力对于控制和自动化更改至关重要。尽管新软件的实现趋势越来越明显，但旧系统和产品的假设是变化很少且很少，因此难以实现自动化变更。作为一个认识到需要以自动化方式公开配置和设置的专业人士，我将使用控制反转（IoC）和依赖注入，脚本安装，测试工具，关注点分离，命令行工具等概念，和基础设施作为代码。





问题你三：







**DevOps做的最重要的事情是什么？** 



DevOps帮助做的最重要的事情是尽可能快地将更改投入生产，同时最大限度地降低软件质量保证和合规性的风险。这是DevOps的主要目标。但是，DevOps还有许多其他积极的副作用。例如，更清晰的沟通和团队之间更好的工作关系，从而创造一个压力较小的工作环境。





问题四：







**DNS中的PTR是什么？** 



指针记录用于将网络接口（IP）映射到主机名。这些主要用于反向DNS。反向DNS的设置与正常（转发）DNS的设置非常相似。当您委派DNS转发时，域的所有者会告知注册商让您的域使用特定的名称服务器。





问题五：







**什么是双因素身份验证？**



双因素身份验证是一种安全过程，其中用户从不同类别的凭证中提供两种识别方法; 一个通常是物理令牌，例如卡，另一个通常是记忆的，例如安全码。





问题六：







**NoSQL数据库相比RDBMS有哪些优势？** 



优点是： 不太需要ETL 支持非结构化文本 能够随时间处理变化 功能广度 能够水平扩展 支持多种数据结构 供应商的选择





问题七：







**DNS中的MX记录是什么？** 



MX记录是用于确定域的电子邮件服务器优先级的邮件交换记录。优先级最低的电子邮件服务器是电子邮件的第一个目标 如果最低优先级的电子邮件服务器不可用，则邮件将发送到优先级较高的电子邮件服务器。





问题八：







**RAID 0和RAID 1有什么区别？**



RAID 1通过镜像提供冗余，即数据写入两个驱动器相同。RAID 0不提供冗余，而是使用条带化，即数据在所有驱动器之间分配。这意味着RAID 0不提供容错功能; 如果任何组成驱动器发生故障，RAID单元将失败。





问题九：







**您将如何准备迁移？** 



回答提示：这个问题评估了您对实际项目的体验，以及它们带来的所有尴尬和复杂性。在您的答案中包括切换，彩排，回滚和前滚，DNS解决方案，功能切换，逐个抽象和自动化等术语。在很少或根本没有现有技术的情况下开发绿地系统总是比处理遗留组件和配置更容易。作为候选人，如果您意识到任何有趣的软件系统实际上将在不断的迁移中，您将看起来适合该角色。





问题十：







**如何确保可追溯性？** 



回答提示：此问题探讨了您对指标，日志记录，交易行程和报告的态度。您应该能够确定该度量标准，监视和日志记录需要成为软件系统的核心部分，如果没有它们，软件基本上无法显示维护和诊断。在你的答案中包括SysLog，Splunk，错误跟踪，Nagios，SCOM，Avicode等词。





问题十一：







**您遇到了哪些问题，以及如何以符合团队目标的方式解决这些问题？** 



回答提示：这个问题的目的是找出你能在工作中处理压力和不合格的程度。谈谈你的领导技能，以处理和激励团队一起解决问题。谈论CI，发布管理和其他工具，以保持跨学科项目的正常进行。





问题十二：







**您成为DevOps工程师需要做哪些特殊培训或教育？** 



回答提示：DevOps更像是一种思维模式或哲学，而不是技能组合。与DevOps Engineers相关的典型技术技能是Linux系统管理，脚本编写以及使用Jenkins和Chef等众多持续集成或配置管理工具之一的经验。这一切归结为，无论你拥有什么技能，重要的是，有能力快速学习新技能以满足需求。这一切都与模式识别有关，并且能够将您的经验与当前需求相结合。熟练掌握Windows和Linux系统管理，脚本开发，理解结构化编程和面向对象设计，以及创建和使用RESTful API的经验需要一个很长的路要走。

# git常见面试题

1. fetch和merge和pull的区别
pull相当于git fetch 和 git merge，即更新远程仓库的代码到本地仓库，然后将内容合并到当前分支。
git fetch：相当于是从远程获取最新版本到本地，不会自动merge
git merge :  将内容合并到当前分支
git pull：相当于是从远程获取最新版本并merge到本地
2. 谈谈tag
tag指向一次commit的id，通常用来给开发分支做一个标记
打标签 : git tag -a v1.01 -m "Relase version 1.01"
提交标签到远程仓库 :  git push origin --tags
查看标签 : git tag
查看某两次tag之间的commit：git log --pretty=oneline tagA..tagB
查看某次tag之后的commit: git log --pretty=oneline tagA..
3. Git和SVN的区别
Git是分布式版本控制系统，SVN是集中式版本控制系统
4. Git工作流程
1、在工作目录中修改某些文件
2、对修改后的文件进行快照，然后保存到暂存区域
3、提交更新，将保存在暂存区域的文件快照永久转储到Git目录中
5. 常用命令
git show # 显示某次提交的内容 git show $id
git add <file> # 将工作文件修改提交到本地暂存区
git rm <file> # 从版本库中删除文件
git reset <file> # 从暂存区恢复到工作文件
git reset HEAD^ # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改
git diff <file> # 比较当前文件和暂存区文件差异 git diff
git log -p <file> # 查看每次详细修改内容的diff
git branch -r # 查看远程分支
git merge <branch> # 将branch分支合并到当前分支
git stash # 暂存
git stash pop #恢复最近一次的暂存
git pull # 抓取远程仓库所有分支更新并合并到本地
git push origin master # 将本地主分支推到远程主分支